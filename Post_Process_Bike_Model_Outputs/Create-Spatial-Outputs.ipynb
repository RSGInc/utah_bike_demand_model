{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "import numpy as np\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "\n",
    "# pd.DataFrame.spatial.from_featureclass(???)\n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA values in Spatially enabled dataframes (ignores SHAPE column)\n",
    "def fill_na_sedf(df_with_shape_column, fill_value=0):\n",
    "    if 'SHAPE' in list(df_with_shape_column.columns):\n",
    "        df = df_with_shape_column.copy()\n",
    "        shape_column = df['SHAPE'].copy()\n",
    "        del df['SHAPE']\n",
    "        return df.fillna(fill_value).merge(shape_column,left_index=True, right_index=True, how='inner')\n",
    "    else:\n",
    "        raise Exception(\"Dataframe does not include 'SHAPE' column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenarios\n",
    "se2024 = ('se2024', r'E:\\Projects\\utah_bike_demand_model_2024')\n",
    "se2024_bb = ('se2024_bb', r'E:\\Projects\\utah_bike_demand_model_2024_BB')\n",
    "se2024_planned = ('se2024_planned', r'E:\\Projects\\utah_bike_demand_model_2024_Planned')\n",
    "se2024_bb_planned = ('se2024_bb_planned', r'E:\\Projects\\utah_bike_demand_model_2024_BB_Planned')\n",
    "se2050 = ('se2050', r'E:\\Projects\\utah_bike_demand_model_2050')\n",
    "se2050_bb = ('se2050_bb', r'E:\\Projects\\utah_bike_demand_model_2050_BB')\n",
    "se2050_planned = ('se2050_planned', r'E:\\Projects\\utah_bike_demand_model_2050_Planned')\n",
    "se2050_bb_planned = ('se2050_bb_planned', r'E:\\Projects\\utah_bike_demand_model_2050_BB_Planned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = se2024_bb_planned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output gdb \n",
    "outputs = [f'{scenario[1]}\\Post_Process_Bike_Model_Outputs\\Outputs', f'{scenario[0]}.gdb']\n",
    "if not os.path.exists(outputs[0]): os.makedirs(outputs[0])\n",
    "gdb = os.path.join(outputs[0], outputs[1])\n",
    "if not arcpy.Exists(gdb): arcpy.CreateFileGDB_management(outputs[0], outputs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Bike volume data to links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jreynolds\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1056: RuntimeWarning: invalid value encountered in cast\n",
      "  if (arr.astype(int) == arr).all():\n",
      "c:\\Users\\jreynolds\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1080: RuntimeWarning: invalid value encountered in cast\n",
      "  if (arr.astype(int) == arr).all():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614362, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'E:\\\\Projects\\\\utah_bike_demand_model_2024_BB_Planned\\\\Post_Process_Bike_Model_Outputs\\\\Outputs\\\\se2024_bb_planned.gdb\\\\links_bike_volume'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in links csv and shapefile\n",
    "links = pd.read_csv(f'{scenario[1]}\\\\Convert_MM_Network\\\\Outputs\\\\links.csv')\n",
    "links_shp = pd.DataFrame.spatial.from_featureclass(f'{scenario[1]}\\\\Convert_MM_Network\\\\Outputs\\\\bike_network.gdb\\\\links')\n",
    "\n",
    "# read in bike volume\n",
    "bike_volume = pd.read_csv(f\"{scenario[1]}\\\\Model_Outputs\\\\bike_vol.csv\")\n",
    "print(bike_volume.shape)\n",
    "\n",
    "# fill bike volume NAs with 0\n",
    "bike_volume['bike_vol'] = bike_volume['bike_vol'].fillna(0)\n",
    "\n",
    "# REMOVE THIS WHEN TABLE BUG IS FIXED\n",
    "bike_volume.dropna(inplace=True)\n",
    "\n",
    "# convert node ids to int\n",
    "bike_volume['from_node'] = bike_volume['from_node'].astype(int)\n",
    "bike_volume['to_node'] = bike_volume['to_node'].astype(int)\n",
    "\n",
    "# Create key to use for joining to links\n",
    "bike_volume['key'] = np.where(bike_volume['from_node'] < bike_volume['to_node'], \n",
    "                              bike_volume['from_node'].astype(str) + \"_\"+ bike_volume['to_node'].astype(str), \n",
    "                              bike_volume['to_node'].astype(str) + \"_\"+ bike_volume['from_node'].astype(str))\n",
    "\n",
    "# Create directional keys\n",
    "bike_volume['ft_key'] = bike_volume['from_node'].astype(str) + \"_\"+ bike_volume['to_node'].astype(str)\n",
    "bike_volume['tf_key'] = bike_volume['to_node'].astype(str) + \"_\"+ bike_volume['from_node'].astype(str)\n",
    "\n",
    "# summarize trips in each direction\n",
    "ft_vol_sum = pd.DataFrame(bike_volume.groupby('ft_key')['bike_vol'].sum())\n",
    "tf_vol_sum = pd.DataFrame(bike_volume.groupby('tf_key')['bike_vol'].sum())\n",
    "\n",
    "ft_vol_sum.columns = ['ft_bvol']\n",
    "tf_vol_sum.columns = ['tf_bvol']\n",
    "\n",
    "# summarize trips in both directions\n",
    "volume_sum = bike_volume.groupby('key', as_index=False)['bike_vol'].sum()\n",
    "volume_sum.rename({'bike_vol':'total_bvol'}, axis=1, inplace=True)\n",
    "\n",
    "#Create FTkey and TF key to use for joining to bike volumes\n",
    "links['key'] = np.where(links['from_node'].astype(int) < links['to_node'].astype(int), \n",
    "                              links['from_node'].astype(str) + \"_\"+ links['to_node'].astype(str), \n",
    "                              links['to_node'].astype(str) + \"_\"+ links['from_node'].astype(str))\n",
    "\n",
    "links[['from_node', 'to_node','key']].head(10)\n",
    "links2 = links[['link_id', 'key']].copy()\n",
    "\n",
    "# join the links with the bike volumes using the common keys\n",
    "link_bike_vol = links2.merge(volume_sum, left_on='key', right_on='key', how='left')\n",
    "link_bike_vol2 = link_bike_vol.merge(ft_vol_sum, left_on='key', right_on='ft_key', how='left')\n",
    "link_bike_vol3 = link_bike_vol2.merge(tf_vol_sum, left_on='key', right_on='tf_key', how='left')\n",
    "\n",
    "link_bike_vol3['link_id'] = link_bike_vol3['link_id'].astype('int64')\n",
    "links4 = links_shp.merge(link_bike_vol3, left_on='link_id', right_on='link_id', how='left')\n",
    "links4['miles_trv'] = links4['Length_Miles'] * links4['total_bvol']\n",
    "links4['miles_trv'] = links4['miles_trv'].round(2)\n",
    "links4 = fill_na_sedf(links4)\n",
    "links4.spatial.to_featureclass(location=os.path.join(gdb,\"links_bike_volume\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize zone trips by Attracting/Producing Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in zones\n",
    "zones_shape = f'{scenario[1]}\\\\Create_Microzones\\\\Outputs\\\\microzones.gdb\\\\microzones'\n",
    "if os.path.exists(zones_shape) == True:\n",
    "   zones_sdf = pd.DataFrame.spatial.from_featureclass(zones_shape) \n",
    "\n",
    "else:\n",
    "    zone_data = pd.read_csv(f'{scenario[1]}\\\\Create_Microzones\\\\Outputs\\\\microzones.csv').astype('Float64')\n",
    "    zones_sdf =  pd.DataFrame.spatial.from_featureclass(r\"E:\\\\Tasks\\MICROZONES\\\\Inputs\\\\Microzones_20240815.shp\")\n",
    "    zones_sdf = zones_sdf[['SHAPE','zone_id']].merge(zone_data, on='zone_id', how='left')\n",
    "    zones_sdf.spatial.to_featureclass(location=zones_shape,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in trip tables, summarize, and format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_zones(trips_df, name):\n",
    "    \n",
    "    # summarize trips by attraction or production\n",
    "    trips_sum_attr = pd.DataFrame(trips_df.groupby('azone')['trips'].sum())\n",
    "    trips_sum_prod = pd.DataFrame(trips_df.groupby('pzone')['trips'].sum())\n",
    "    \n",
    "    # format tables\n",
    "    trips_sum_attr['zone_id'] = trips_sum_attr.index\n",
    "    trips_sum_attr.columns = [name + '_abk', 'zone_id']\n",
    "    trips_sum_prod['zone_id'] = trips_sum_prod.index\n",
    "    trips_sum_prod.columns = [name + '_pbk', 'zone_id']\n",
    "    \n",
    "    # join the attraction and production summary tables using zone id\n",
    "    merged = trips_sum_attr.merge(trips_sum_prod, left_on='zone_id', right_on='zone_id', how='outer')\n",
    "    return merged\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretionary trips (social trips, some recreation)\n",
    "disc = pd.read_csv(os.path.join(scenario[1], \"Model_Outputs\", \"disc_trip.parquet\"))\n",
    "disc_sum = summarize_zones(disc, 'disc')\n",
    "del disc\n",
    "\n",
    "# Maintenance trips (e.g. groceries)\n",
    "maint = pd.read_csv(os.path.join(scenario[1], \"Model_Outputs\", \"maint_trip.parquet\"))\n",
    "maint_sum = summarize_zones(maint, 'mnt')\n",
    "del maint\n",
    "\n",
    "# Maintenance trips non-home-based (e.g. groceries)\n",
    "maint_nhb = pd.read_csv(os.path.join(scenario[1], \"Model_Outputs\", \"maint_nhb_trip.parquet\"))\n",
    "maint_nhb_sum = summarize_zones(maint_nhb, 'mntnhb')\n",
    "del maint_nhb\n",
    "\n",
    "# Recreational family trips\n",
    "rec_fam = pd.read_csv(os.path.join(scenario[1], \"Model_Outputs\", \"rec_fam_trip.parquet\"))\n",
    "rec_fam_sum = summarize_zones(rec_fam, 'recfam')\n",
    "del rec_fam\n",
    "\n",
    "# Recreation long trips\n",
    "rec_long = pd.read_csv(os.path.join(scenario[1], \"Model_Outputs\", \"rec_long_trip.parquet\"))\n",
    "rec_long_sum = summarize_zones(rec_long, 'reclng')\n",
    "del rec_long\n",
    "\n",
    "# Recreation mountain bike trips\n",
    "rec_mtb = pd.read_csv(os.path.join(scenario[1], \"Model_Outputs\", \"rec_mtb_trip.parquet\"))\n",
    "rec_mtb_sum = summarize_zones(rec_mtb, 'recmtb')\n",
    "del rec_mtb\n",
    "\n",
    "# Recreation other trips (recreation that doesn't fall into family or long)\n",
    "rec_oth = pd.read_csv(os.path.join(scenario[1], \"Model_Outputs\", \"rec_oth_trip.parquet\"))\n",
    "rec_oth_sum = summarize_zones(rec_oth, 'recoth')\n",
    "del rec_oth\n",
    "\n",
    "# School (grade) trips\n",
    "sch_grade = pd.read_csv(os.path.join(scenario[1], \"Model_Outputs\", \"sch_grade_trip.parquet\"))\n",
    "sch_grade_sum = summarize_zones(sch_grade, 'grade')\n",
    "del sch_grade\n",
    "\n",
    "# School (university) trips\n",
    "sch_univ = pd.read_csv(os.path.join(scenario[1], \"Model_Outputs\", \"sch_univ_trip.parquet\"))\n",
    "sch_univ_sum = summarize_zones(sch_univ, 'univ')\n",
    "del sch_univ\n",
    "\n",
    "# Work trips\n",
    "work = pd.read_csv(os.path.join(scenario[1], \"Model_Outputs\", \"work_trip.parquet\"))\n",
    "work_sum = summarize_zones(work, 'wrk')\n",
    "del work\n",
    "\n",
    "# Work non-home-based trips\n",
    "work_nhb = pd.read_csv(os.path.join(scenario[1], \"Model_Outputs\", \"work_nhb_trip.parquet\"))\n",
    "work_nhb_sum = summarize_zones(work_nhb, 'wrknhb')\n",
    "del work_nhb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge trip summaries back to microzone shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean copy of zones dataset\n",
    "zones2 = zones_sdf[['zone_id', 'area_sqmil', 'SHAPE']].copy()\n",
    "zones2['zone_id'] = zones2['zone_id'].astype('int64')\n",
    "\n",
    "# Join trip tables\n",
    "zones2 = zones2.merge(disc_sum, left_on='zone_id', right_on='zone_id', how='left')\n",
    "zones2 = zones2.merge(maint_sum, left_on='zone_id', right_on='zone_id', how='left')\n",
    "zones2 = zones2.merge(maint_nhb_sum, left_on='zone_id', right_on='zone_id', how='left')\n",
    "zones2 = zones2.merge(rec_fam_sum, left_on='zone_id', right_on='zone_id', how='left')\n",
    "zones2 = zones2.merge(rec_long_sum, left_on='zone_id', right_on='zone_id', how='left')\n",
    "zones2 = zones2.merge(rec_mtb_sum, left_on='zone_id', right_on='zone_id', how='left')\n",
    "zones2 = zones2.merge(rec_oth_sum, left_on='zone_id', right_on='zone_id', how='left')\n",
    "zones2 = zones2.merge(sch_grade_sum, left_on='zone_id', right_on='zone_id', how='left')\n",
    "zones2 = zones2.merge(sch_univ_sum, left_on='zone_id', right_on='zone_id', how='left')\n",
    "zones2 = zones2.merge(work_sum, left_on='zone_id', right_on='zone_id', how='left')\n",
    "zones2 = zones2.merge(work_nhb_sum, left_on='zone_id', right_on='zone_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Projects\\\\utah_bike_demand_model_2024_BB_Planned\\\\Post_Process_Bike_Model_Outputs\\\\Outputs\\\\se2024_bb_planned.gdb\\\\Microzone_Trip_Summaries'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill NAs where necessary\n",
    "zones2 = fill_na_sedf(zones2)\n",
    "\n",
    "# calc totals        \n",
    "zones2['total_abk'] = (zones2['disc_abk'] + zones2['mnt_abk'] + zones2['mntnhb_abk'] + \n",
    "                       zones2['recfam_abk'] + zones2['reclng_abk'] + zones2['recmtb_abk'] + zones2['recoth_abk'] + \n",
    "                       zones2['grade_abk'] + zones2['univ_abk'] + zones2['wrk_abk'] + zones2['wrknhb_abk']) \n",
    "\n",
    "zones2['total_pbk'] = (zones2['disc_pbk'] + zones2['mnt_pbk'] + zones2['mntnhb_pbk'] + \n",
    "                       zones2['recfam_pbk'] + zones2['reclng_pbk'] + zones2['recmtb_pbk'] + zones2['recoth_pbk'] + \n",
    "                       zones2['grade_pbk'] + zones2['univ_pbk'] + zones2['wrk_pbk'] + zones2['wrknhb_pbk']) \n",
    "\n",
    "zones2.spatial.to_featureclass(location=os.path.join(gdb,\"Microzone_Trip_Summaries\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge zone attraction and production scores with the microzone geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Projects\\\\utah_bike_demand_model_2024_BB_Planned\\\\Post_Process_Bike_Model_Outputs\\\\Outputs\\\\se2024_bb_planned.gdb\\\\Microzone_P_Scores'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a clean copy of zones dataset\n",
    "zones2 = zones_sdf[['zone_id', 'area_sqmil', 'SHAPE']].copy()\n",
    "zones2['zone_id'] = zones2['zone_id'].astype('int64')\n",
    "\n",
    "# NOTE: need to add zone_id to empty field in output csv\n",
    "ascore = pd.read_csv(os.path.join(scenario[1], 'Model_Outputs','zone_attraction_size.csv'))\n",
    "pscore = pd.read_csv(os.path.join(scenario[1], 'Model_Outputs','zone_production_size.csv'))\n",
    "\n",
    "ascore = ascore.rename(columns={\"Unnamed: 0\": \"zone_id\"})\n",
    "pscore = pscore.rename(columns={\"Unnamed: 0\": \"zone_id\"})\n",
    "\n",
    "zones3a = zones2.merge(ascore, left_on='zone_id', right_on='zone_id', how='left')\n",
    "zones3p = zones2.merge(pscore, left_on='zone_id', right_on='zone_id', how='left')\n",
    "\n",
    "# fill NAs where necessary\n",
    "zones3a = fill_na_sedf(zones3a)\n",
    "zones3p = fill_na_sedf(zones3p)\n",
    "\n",
    "zones3p.rename({'sch_grade_nhb': 'grade_nhb', 'sch_univ_nhb': 'univ_nhb', 'rec_oth_nhb':'recothnhb'}, axis=1, inplace=True)        \n",
    "        \n",
    "# Fill NAs with -1, then export to shape\n",
    "zones3a.spatial.to_featureclass(location=os.path.join(gdb,\"Microzone_A_Scores\"))\n",
    "zones3p.spatial.to_featureclass(location=os.path.join(gdb,\"Microzone_P_Scores\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Centroid Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Projects\\\\utah_bike_demand_model_2024_BB_Planned\\\\Post_Process_Bike_Model_Outputs\\\\Outputs\\\\se2024_bb_planned.gdb\\\\Microzone_Centroids'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = pd.DataFrame.spatial.from_featureclass(os.path.join(scenario[1], 'Convert_MM_Network', 'Outputs', 'nodes.shp'))\n",
    "nodes['node_id'] = nodes.index\n",
    "nodes2 = nodes[['node_id', 'xcoord', 'ycoord', 'zcoord', 'SHAPE']].copy()\n",
    "zones_sdf.rename({'NODE_ID':'node_id'}, axis=1, inplace=True)\n",
    "centroids = nodes2.merge(zones_sdf[['node_id', 'zone_id']], on='node_id', how='inner')\n",
    "centroids = centroids[['node_id', 'xcoord', 'ycoord', 'zcoord', 'zone_id', 'SHAPE']].copy()\n",
    "centroids.spatial.to_featureclass(location=os.path.join(gdb,\"Microzone_Centroids\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
